{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a43d03",
   "metadata": {},
   "source": [
    "# Gait Deterioration Patterns During the 6-Minute Walk Test: Discriminating Fallers from Non-Fallers\n",
    "\n",
    "**Author:** Ferdinand Delgado, PhD  \n",
    "**Affiliation:** Move, Measure, Analyze LLC  \n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project examines whether **gait deterioration patterns** during the 6-minute walk test (6MWT) can discriminate between older adults who have experienced falls and those who have not. Rather than relying on overall gait averages, this analysis segments each participant's gait cycles into **temporal quarters** (Q1–Q4) to capture fatigue-related changes that may reveal underlying stability deficits.\n",
    "\n",
    "**Key Idea:** Fallers may not differ from non-fallers at the start of a walk, but their gait may deteriorate differently as fatigue accumulates. The *pattern of change* across the walk may be more informative than any single metric.\n",
    "\n",
    "### Analytical Approach\n",
    "1. Parse raw cycle-by-cycle gait data from IMU-based gait analysis (APDM Mobility Lab)\n",
    "2. Segment each participant's gait cycles into quarters (Q1–Q4) based on their individual cycle count\n",
    "3. Engineer features capturing fatigue effects: quarter means, Q4–Q1 differences, linear slope across quarters, and within-quarter variability\n",
    "4. Compare fallers vs. non-fallers using appropriate statistical tests with assumption checking\n",
    "5. Identify the most discriminating features and build a parsimonious classification model\n",
    "\n",
    "### Dataset\n",
    "- **N = 60** community-dwelling older adults\n",
    "- **23 fallers** (experienced ≥1 fall in the past year) vs. **37 non-fallers**\n",
    "- **6-minute walk test** with cycle-by-cycle gait metrics from APDM Mobility Lab wearable sensors\n",
    "- **34 gait metrics** including speed, cadence, stride length, double support time, asymmetry, trunk/lumbar ROM, and arm swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ecfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, levene, mannwhitneyu, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 11,\n",
    "    'figure.dpi': 120,\n",
    "})\n",
    "\n",
    "GOLD = '#c5a55a'\n",
    "BLACK = '#1a1a1a'\n",
    "GRAY = '#888888'\n",
    "FALLER_COLOR = '#d64545'\n",
    "NON_FALLER_COLOR = '#3a86a8'\n",
    "\n",
    "print(\"All packages loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca03c55",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preparation\n",
    "\n",
    "The raw walk trial CSV files from APDM Mobility Lab contain cycle-by-cycle values for each gait metric. Each row is a metric, and each column (after the first five) is an individual gait cycle. Participant demographics and fall history are stored in a separate REDCap export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f96749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demographics\n",
    "demo = pd.read_csv('data/demographics.csv')\n",
    "print(f\"Participants: {len(demo)}\")\n",
    "print(f\"\\nFall Status Distribution:\")\n",
    "print(demo['Experienced a fall in past year'].value_counts())\n",
    "print(f\"\\nAge: Mean = {demo['Age (years)'].mean():.1f} ± {demo['Age (years)'].std():.1f} years\")\n",
    "print(f\"Sex: {demo['Biological Sex'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_walk_trial_csv(filepath):\n",
    "    \"\"\"Parse APDM Mobility Lab walk trial CSV into metadata and cycle-by-cycle data.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Extract metadata from header rows\n",
    "    metadata = {}\n",
    "    for line in lines[:15]:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) >= 2:\n",
    "            metadata[parts[0].strip('\"')] = parts[1].strip('\"')\n",
    "    \n",
    "    # Find the data header row\n",
    "    header_row = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('\"Measure\"'):\n",
    "            header_row = i\n",
    "            break\n",
    "    \n",
    "    if header_row is None:\n",
    "        raise ValueError(\"Could not find header row in CSV\")\n",
    "    \n",
    "    # Parse cycle-by-cycle values for each metric\n",
    "    data = {}\n",
    "    for line in lines[header_row + 1:]:\n",
    "        parts = line.strip().split(',')\n",
    "        if len(parts) > 5:\n",
    "            measure = parts[0].strip('\"')\n",
    "            vals = []\n",
    "            for v in parts[5:]:  # Skip Measure, Normative Mean/SD, Mean, SD\n",
    "                v = v.strip('\"')\n",
    "                try:\n",
    "                    vals.append(float(v) if v else np.nan)\n",
    "                except ValueError:\n",
    "                    vals.append(np.nan)\n",
    "            data[measure] = vals\n",
    "    \n",
    "    return metadata, data\n",
    "\n",
    "# Test with one file\n",
    "meta, data = parse_walk_trial_csv('data/walk_trials/20251212-104206EST_Walk_Trial.csv')\n",
    "print(f\"Subject ID: {meta.get('Subject Public ID')}\")\n",
    "print(f\"Condition: {meta.get('Condition')}\")\n",
    "print(f\"Gait metrics available: {len(data)}\")\n",
    "\n",
    "# Show an example metric\n",
    "example_metric = 'Gait - Lower Limb - Gait Speed L (m/s)'\n",
    "if example_metric in data:\n",
    "    valid_cycles = [x for x in data[example_metric] if not np.isnan(x)]\n",
    "    print(f\"\\n{example_metric}:\")\n",
    "    print(f\"  Total gait cycles: {len(valid_cycles)}\")\n",
    "    print(f\"  Mean: {np.mean(valid_cycles):.3f} m/s\")\n",
    "    print(f\"  Range: {np.min(valid_cycles):.3f} – {np.max(valid_cycles):.3f} m/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105af4a",
   "metadata": {},
   "source": [
    "## 2. Quarters Segmentation\n",
    "\n",
    "The central methodological contribution of this analysis is segmenting the 6-minute walk into **temporal quarters**. Each participant's total gait cycles are divided into four equal (or near-equal) segments:\n",
    "\n",
    "- **Q1** — Early walk (fresh, baseline performance)\n",
    "- **Q2** — Early-mid walk\n",
    "- **Q3** — Late-mid walk  \n",
    "- **Q4** — Late walk (fatigued, end-of-test performance)\n",
    "\n",
    "This is done per-participant since individuals with different cadences produce different numbers of cycles during the fixed 6-minute duration. A participant with 152 cycles gets ~38 per quarter; someone with 100 cycles gets ~25 per quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d53c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_quarters(cycle_data):\n",
    "    \"\"\"\n",
    "    Split cycle-by-cycle data into four temporal quarters.\n",
    "    \n",
    "    Each participant's valid gait cycles are divided into 4 equal segments.\n",
    "    Remainder cycles are distributed to later quarters (Q4 gets extras first),\n",
    "    reflecting that the end of the walk is where fatigue effects accumulate.\n",
    "    \n",
    "    Returns None if fewer than 8 valid cycles (minimum 2 per quarter).\n",
    "    \"\"\"\n",
    "    valid = [x for x in cycle_data if not np.isnan(x)]\n",
    "    n = len(valid)\n",
    "    \n",
    "    if n < 8:\n",
    "        return None\n",
    "    \n",
    "    q_size = n // 4\n",
    "    remainder = n % 4\n",
    "    sizes = [q_size] * 4\n",
    "    for i in range(remainder):\n",
    "        sizes[3 - i] += 1  # Distribute remainder to later quarters\n",
    "    \n",
    "    quarters = []\n",
    "    start = 0\n",
    "    for s in sizes:\n",
    "        quarters.append(np.array(valid[start:start + s]))\n",
    "        start += s\n",
    "    \n",
    "    return quarters\n",
    "\n",
    "\n",
    "def calculate_quarter_features(quarters):\n",
    "    \"\"\"\n",
    "    Engineer features from quarterly gait data.\n",
    "    \n",
    "    For each quarter:\n",
    "      - Mean, SD, CV (within-quarter variability)\n",
    "    \n",
    "    Across quarters:\n",
    "      - Q4 - Q1 difference (fatigue magnitude)\n",
    "      - Q4 - Q1 percent change (relative fatigue)\n",
    "      - Linear slope Q1→Q4 (deterioration rate)\n",
    "      - Slope R² (linearity of deterioration)\n",
    "      - Overall mean, SD, CV\n",
    "    \"\"\"\n",
    "    if quarters is None:\n",
    "        return None\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Per-quarter statistics\n",
    "    for i, q in enumerate(quarters, 1):\n",
    "        features[f'Q{i}_mean'] = np.mean(q)\n",
    "        features[f'Q{i}_sd'] = np.std(q, ddof=1)\n",
    "        features[f'Q{i}_cv'] = (np.std(q, ddof=1) / abs(np.mean(q)) * 100) if np.mean(q) != 0 else np.nan\n",
    "        features[f'Q{i}_n'] = len(q)\n",
    "    \n",
    "    # Fatigue features\n",
    "    features['Q4_Q1_diff'] = features['Q4_mean'] - features['Q1_mean']\n",
    "    features['Q4_Q1_pct'] = ((features['Q4_mean'] - features['Q1_mean']) / abs(features['Q1_mean']) * 100) if features['Q1_mean'] != 0 else np.nan\n",
    "    \n",
    "    # Linear trend across quarters\n",
    "    q_means = [features[f'Q{i}_mean'] for i in range(1, 5)]\n",
    "    slope, intercept, r, p, se = stats.linregress([1, 2, 3, 4], q_means)\n",
    "    features['slope'] = slope\n",
    "    features['slope_r2'] = r ** 2\n",
    "    \n",
    "    # Overall statistics\n",
    "    all_data = np.concatenate(quarters)\n",
    "    features['overall_mean'] = np.mean(all_data)\n",
    "    features['overall_sd'] = np.std(all_data, ddof=1)\n",
    "    features['overall_cv'] = (features['overall_sd'] / abs(features['overall_mean']) * 100) if features['overall_mean'] != 0 else np.nan\n",
    "    features['total_cycles'] = len(all_data)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# Demonstrate on example data\n",
    "example_cycles = data[example_metric]\n",
    "quarters = split_into_quarters(example_cycles)\n",
    "features = calculate_quarter_features(quarters)\n",
    "\n",
    "print(f\"Example: {example_metric}\")\n",
    "print(f\"{'─' * 50}\")\n",
    "for i in range(1, 5):\n",
    "    print(f\"  Q{i}: Mean = {features[f'Q{i}_mean']:.3f}, SD = {features[f'Q{i}_sd']:.3f}, n = {features[f'Q{i}_n']:.0f}\")\n",
    "print(f\"{'─' * 50}\")\n",
    "print(f\"  Q4 − Q1 diff:    {features['Q4_Q1_diff']:+.4f}\")\n",
    "print(f\"  Q4 − Q1 change:  {features['Q4_Q1_pct']:+.2f}%\")\n",
    "print(f\"  Linear slope:     {features['slope']:+.5f}\")\n",
    "print(f\"  Slope R²:         {features['slope_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79948dbd",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction — All Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f85a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Key gait metrics to analyze\n",
    "KEY_METRICS = [\n",
    "    'Gait - Lower Limb - Gait Speed L (m/s)',\n",
    "    'Gait - Lower Limb - Gait Speed R (m/s)',\n",
    "    'Gait - Lower Limb - Cadence L (steps/min)',\n",
    "    'Gait - Lower Limb - Cadence R (steps/min)',\n",
    "    'Gait - Lower Limb - Stride Length L (m)',\n",
    "    'Gait - Lower Limb - Stride Length R (m)',\n",
    "    'Gait - Lower Limb - Double Support L (%GCT)',\n",
    "    'Gait - Lower Limb - Double Support R (%GCT)',\n",
    "    'Gait - Lower Limb - Single Limb Support L (%GCT)',\n",
    "    'Gait - Lower Limb - Single Limb Support R (%GCT)',\n",
    "    'Gait - Lower Limb - Stance L (%GCT)',\n",
    "    'Gait - Lower Limb - Swing L (%GCT)',\n",
    "    'Gait - Lower Limb - Step Duration L (s)',\n",
    "    'Gait - Lower Limb - Gait Cycle Duration L (s)',\n",
    "    'Gait - Lower Limb - Gait Speed Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Cadence Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Double Support Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Single Limb Support Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Stride Length Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Step Duration Asymmetry (%Diff)',\n",
    "    'Gait - Lower Limb - Foot Strike Angle L (degrees)',\n",
    "    'Gait - Lower Limb - Foot Strike Angle R (degrees)',\n",
    "    'Gait - Lower Limb - Toe Off Angle L (degrees)',\n",
    "    'Gait - Lower Limb - Toe Off Angle R (degrees)',\n",
    "    'Gait - Lower Limb - Elevation at Midswing L (cm)',\n",
    "    'Gait - Lower Limb - Circumduction L (cm)',\n",
    "    'Gait - Lumbar - Coronal Range of Motion (degrees)',\n",
    "    'Gait - Lumbar - Sagittal Range of Motion (degrees)',\n",
    "    'Gait - Lumbar - Transverse Range of Motion (degrees)',\n",
    "    'Gait - Trunk - Coronal Range of Motion (degrees)',\n",
    "    'Gait - Trunk - Sagittal Range of Motion (degrees)',\n",
    "    'Gait - Upper Limb - Arm Swing Velocity L (degrees/s)',\n",
    "    'Gait - Upper Limb - Arm Swing Velocity R (degrees/s)',\n",
    "    'Gait - Upper Limb - Arm Range of Motion L (degrees)',\n",
    "]\n",
    "\n",
    "def shorten_metric_name(metric):\n",
    "    \"\"\"Create a concise feature name from the full APDM metric label.\"\"\"\n",
    "    short = metric.replace('Gait - Lower Limb - ', 'LL_')\n",
    "    short = short.replace('Gait - Lumbar - ', 'Lumb_')\n",
    "    short = short.replace('Gait - Trunk - ', 'Trunk_')\n",
    "    short = short.replace('Gait - Upper Limb - ', 'UL_')\n",
    "    for unit in ['(%GCT)', '(m/s)', '(steps/min)', '(degrees/s)', '(degrees)', '(%Diff)', '(cm)', '(m)', '(s)']:\n",
    "        short = short.replace(f' {unit}', '')\n",
    "    return short.replace(' ', '_')\n",
    "\n",
    "\n",
    "# Process all walk trial files\n",
    "trial_files = sorted(glob.glob('data/walk_trials/*_Walk_Trial.csv'))\n",
    "print(f\"Walk trial files found: {len(trial_files)}\")\n",
    "\n",
    "all_results = []\n",
    "for fp in trial_files:\n",
    "    try:\n",
    "        meta, data = parse_walk_trial_csv(fp)\n",
    "        sid = int(meta.get('Subject Public ID', 0))\n",
    "        if sid == 0:\n",
    "            continue\n",
    "        \n",
    "        row = {'Subject_ID': sid}\n",
    "        \n",
    "        for metric in KEY_METRICS:\n",
    "            if metric in data:\n",
    "                quarters = split_into_quarters(data[metric])\n",
    "                feats = calculate_quarter_features(quarters)\n",
    "                if feats:\n",
    "                    short = shorten_metric_name(metric)\n",
    "                    for fn, fv in feats.items():\n",
    "                        row[f'{short}__{fn}'] = fv\n",
    "        \n",
    "        all_results.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {os.path.basename(fp)}: {e}\")\n",
    "\n",
    "results = pd.DataFrame(all_results)\n",
    "\n",
    "# Merge with demographics\n",
    "demo_sub = demo[['Participant ID', 'Age (years)', 'Biological Sex', 'Experienced a fall in past year']].copy()\n",
    "demo_sub.columns = ['Subject_ID', 'Age', 'Sex', 'Fall_Status']\n",
    "demo_sub['Faller'] = (demo_sub['Fall_Status'] == 'Yes').astype(int)\n",
    "\n",
    "results = results.merge(demo_sub, on='Subject_ID', how='left')\n",
    "\n",
    "feat_cols = [c for c in results.columns if '__' in c]\n",
    "print(f\"\\nParticipants processed: {len(results)}\")\n",
    "print(f\"  Fallers: {results['Faller'].sum()}\")\n",
    "print(f\"  Non-Fallers: {(results['Faller'] == 0).sum()}\")\n",
    "print(f\"Features extracted: {len(feat_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfadb8",
   "metadata": {},
   "source": [
    "## 4. Visualization — Gait Trajectories Across Quarters\n",
    "\n",
    "If fallers deteriorate differently than non-fallers, we should see the groups diverge across Q1 → Q4. Let's visualize this for key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quarter_trajectories(results, metrics_to_plot, title_prefix=''):\n",
    "    \"\"\"Plot mean ± SE quarter trajectories for fallers vs non-fallers.\"\"\"\n",
    "    fallers = results[results['Faller'] == 1]\n",
    "    non_fallers = results[results['Faller'] == 0]\n",
    "    \n",
    "    n_metrics = len(metrics_to_plot)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4 * n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for idx, metric_short in enumerate(metrics_to_plot):\n",
    "        ax = axes_flat[idx]\n",
    "        \n",
    "        for group, color, label in [(fallers, FALLER_COLOR, 'Fallers'), \n",
    "                                     (non_fallers, NON_FALLER_COLOR, 'Non-Fallers')]:\n",
    "            means = []\n",
    "            ses = []\n",
    "            for q in range(1, 5):\n",
    "                col = f'{metric_short}__Q{q}_mean'\n",
    "                if col in group.columns:\n",
    "                    vals = group[col].dropna()\n",
    "                    means.append(vals.mean())\n",
    "                    ses.append(vals.std() / np.sqrt(len(vals)))\n",
    "                else:\n",
    "                    means.append(np.nan)\n",
    "                    ses.append(np.nan)\n",
    "            \n",
    "            x = [1, 2, 3, 4]\n",
    "            ax.errorbar(x, means, yerr=ses, marker='o', markersize=6,\n",
    "                       color=color, linewidth=2, capsize=4, label=label)\n",
    "        \n",
    "        # Clean metric name for title\n",
    "        display_name = metric_short.replace('LL_', '').replace('Lumb_', 'Lumbar ').replace('Trunk_', 'Trunk ').replace('UL_', 'Arm ').replace('_', ' ')\n",
    "        ax.set_title(display_name, fontsize=11, fontweight='500')\n",
    "        ax.set_xticks([1, 2, 3, 4])\n",
    "        ax.set_xticklabels(['Q1\\n(Fresh)', 'Q2', 'Q3', 'Q4\\n(Fatigued)'])\n",
    "        ax.set_xlabel('')\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(metrics_to_plot), len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "    \n",
    "    axes_flat[0].legend(framealpha=0.9, fontsize=9)\n",
    "    fig.suptitle(f'{title_prefix}Gait Quarter Trajectories: Fallers vs Non-Fallers (Mean ± SE)', \n",
    "                 fontsize=14, fontweight='600', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/quarter_trajectories.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Select key metrics to visualize\n",
    "key_plot_metrics = [\n",
    "    'LL_Gait_Speed_L', 'LL_Stride_Length_L', 'LL_Cadence_L',\n",
    "    'LL_Double_Support_L', 'LL_Gait_Speed_Asymmetry', 'LL_Stride_Length_Asymmetry',\n",
    "    'Trunk_Sagittal_Range_of_Motion', 'Lumb_Coronal_Range_of_Motion', 'UL_Arm_Swing_Velocity_L',\n",
    "]\n",
    "\n",
    "plot_quarter_trajectories(results, key_plot_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad6f727",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis — Group Comparisons\n",
    "\n",
    "For each extracted feature, we perform:\n",
    "1. **Normality testing** (Shapiro-Wilk) for both groups\n",
    "2. **Variance homogeneity** (Levene's test)\n",
    "3. **Appropriate group comparison**: Student's t (parametric, equal variance), Welch's t (parametric, unequal variance), or Mann-Whitney U (non-parametric)\n",
    "4. **Effect sizes**: Hedge's g (parametric) or rank-biserial r (non-parametric)\n",
    "5. **Multiple comparison correction**: Benjamini-Hochberg FDR at α = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5dcda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups(f_data, nf_data):\n",
    "    \"\"\"Run assumption-appropriate statistical comparison between groups.\"\"\"\n",
    "    f = f_data.dropna().values\n",
    "    nf = nf_data.dropna().values\n",
    "    \n",
    "    if len(f) < 3 or len(nf) < 3:\n",
    "        return None\n",
    "    \n",
    "    # Assumption checks\n",
    "    f_shapiro_p = shapiro(f)[1]\n",
    "    nf_shapiro_p = shapiro(nf)[1]\n",
    "    levene_p = levene(f, nf)[1]\n",
    "    \n",
    "    # Select test based on assumptions\n",
    "    if f_shapiro_p >= 0.05 and nf_shapiro_p >= 0.05:\n",
    "        if levene_p >= 0.05:\n",
    "            stat, p = ttest_ind(f, nf, equal_var=True)\n",
    "            test = \"Student's t\"\n",
    "        else:\n",
    "            stat, p = ttest_ind(f, nf, equal_var=False)\n",
    "            test = \"Welch's t\"\n",
    "        # Hedge's g\n",
    "        n1, n2 = len(f), len(nf)\n",
    "        pooled_sd = np.sqrt(((n1-1)*np.var(f, ddof=1) + (n2-1)*np.var(nf, ddof=1)) / (n1+n2-2))\n",
    "        d = (np.mean(f) - np.mean(nf)) / pooled_sd if pooled_sd > 0 else 0\n",
    "        g = d * (1 - 3 / (4*(n1+n2) - 9))  # Hedge's correction\n",
    "        effect, effect_type = g, \"Hedge's g\"\n",
    "    else:\n",
    "        stat, p = mannwhitneyu(f, nf, alternative='two-sided')\n",
    "        test = \"Mann-Whitney U\"\n",
    "        r = 1 - (2 * stat) / (len(f) * len(nf))\n",
    "        effect, effect_type = r, \"rank-biserial r\"\n",
    "    \n",
    "    # Effect size interpretation\n",
    "    es = abs(effect)\n",
    "    if 'g' in effect_type:\n",
    "        interp = 'Negligible' if es < 0.2 else 'Small' if es < 0.5 else 'Medium' if es < 0.8 else 'Large'\n",
    "    else:\n",
    "        interp = 'Negligible' if es < 0.1 else 'Small' if es < 0.3 else 'Medium' if es < 0.5 else 'Large'\n",
    "    \n",
    "    return {\n",
    "        'test': test, 'statistic': stat, 'p_value': p,\n",
    "        'effect_size': effect, 'effect_type': effect_type, 'effect_interp': interp,\n",
    "        'f_shapiro_p': f_shapiro_p, 'nf_shapiro_p': nf_shapiro_p, 'levene_p': levene_p\n",
    "    }\n",
    "\n",
    "\n",
    "# Run comparisons on all features\n",
    "fallers = results[results['Faller'] == 1]\n",
    "non_fallers = results[results['Faller'] == 0]\n",
    "\n",
    "comparison_rows = []\n",
    "for col in feat_cols:\n",
    "    comp = compare_groups(fallers[col], non_fallers[col])\n",
    "    if comp:\n",
    "        comparison_rows.append({\n",
    "            'Feature': col,\n",
    "            'Fallers_Mean': fallers[col].mean(),\n",
    "            'Fallers_SD': fallers[col].std(),\n",
    "            'NonFallers_Mean': non_fallers[col].mean(),\n",
    "            'NonFallers_SD': non_fallers[col].std(),\n",
    "            **comp\n",
    "        })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_rows)\n",
    "\n",
    "# FDR correction\n",
    "from scipy.stats import rankdata\n",
    "p_vals = comp_df['p_value'].values\n",
    "ranks = rankdata(p_vals)\n",
    "n_tests = len(p_vals)\n",
    "fdr_threshold = ranks / n_tests * 0.05\n",
    "comp_df['FDR_threshold'] = fdr_threshold\n",
    "comp_df['Sig_uncorrected'] = comp_df['p_value'] < 0.05\n",
    "comp_df['Sig_FDR'] = comp_df['p_value'] <= comp_df['FDR_threshold']\n",
    "\n",
    "# Sort by absolute effect size\n",
    "comp_df['abs_effect'] = comp_df['effect_size'].abs()\n",
    "comp_df = comp_df.sort_values('abs_effect', ascending=False)\n",
    "\n",
    "print(f\"Features tested: {len(comp_df)}\")\n",
    "print(f\"Significant (p < 0.05, uncorrected): {comp_df['Sig_uncorrected'].sum()}\")\n",
    "print(f\"Significant (FDR corrected):         {comp_df['Sig_FDR'].sum()}\")\n",
    "print(f\"\\n{'─' * 90}\")\n",
    "print(f\"{'TOP 15 DISCRIMINATING FEATURES (by effect size)':^90}\")\n",
    "print(f\"{'─' * 90}\")\n",
    "\n",
    "display_cols = ['Feature', 'effect_size', 'effect_type', 'effect_interp', 'p_value', 'test', 'Sig_uncorrected', 'Sig_FDR']\n",
    "print(comp_df[display_cols].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c31e48a",
   "metadata": {},
   "source": [
    "## 6. Effect Size Forest Plot\n",
    "\n",
    "A forest plot of the top discriminating features ranked by effect size — this shows *which* gait characteristics differ most between fallers and non-fallers, and whether those differences are clinically meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot of top features by effect size\n",
    "top_n = 20\n",
    "top_features = comp_df.head(top_n).copy()\n",
    "top_features = top_features.iloc[::-1]  # Reverse for bottom-to-top plotting\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Clean feature names for display\n",
    "def clean_feature_name(name):\n",
    "    parts = name.split('__')\n",
    "    metric = parts[0].replace('LL_', '').replace('Lumb_', 'Lumbar ').replace('Trunk_', 'Trunk ').replace('UL_', 'Arm ').replace('_', ' ')\n",
    "    feature_type = parts[1] if len(parts) > 1 else ''\n",
    "    return f\"{metric} — {feature_type}\"\n",
    "\n",
    "labels = [clean_feature_name(f) for f in top_features['Feature']]\n",
    "effects = top_features['effect_size'].values\n",
    "colors = [FALLER_COLOR if top_features.iloc[i]['Sig_uncorrected'] else GRAY for i in range(len(top_features))]\n",
    "\n",
    "y_pos = range(len(labels))\n",
    "ax.barh(y_pos, effects, color=colors, height=0.7, edgecolor='white', linewidth=0.5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels, fontsize=8)\n",
    "ax.axvline(x=0, color=BLACK, linewidth=0.8)\n",
    "ax.set_xlabel('Effect Size', fontsize=11)\n",
    "ax.set_title(f'Top {top_n} Discriminating Features: Fallers vs Non-Fallers', fontsize=13, fontweight='600')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=FALLER_COLOR, label='p < 0.05'),\n",
    "                   Patch(facecolor=GRAY, label='p ≥ 0.05')]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/effect_size_forest_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08946f1f",
   "metadata": {},
   "source": [
    "## 7. Classification — Logistic Regression with LOO Cross-Validation\n",
    "\n",
    "Using the top discriminating features, we build a parsimonious logistic regression model and evaluate it with Leave-One-Out cross-validation (appropriate for small samples). We deliberately limit the model to 2–3 predictors to avoid overfitting with n=60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features for classification (limit to 2-3 to avoid overfitting)\n",
    "# Choose features that are conceptually distinct (not redundant)\n",
    "candidate_features = comp_df.head(30)\n",
    "\n",
    "# Pick features from different categories to minimize collinearity\n",
    "# We'll select the top feature from: speed/efficiency, variability, and asymmetry\n",
    "speed_feats = [f for f in candidate_features['Feature'] if any(k in f for k in ['Gait_Speed', 'Stride_Length', 'Cadence'])]\n",
    "variability_feats = [f for f in candidate_features['Feature'] if any(k in f for k in ['cv', 'sd', 'slope'])]\n",
    "asymmetry_feats = [f for f in candidate_features['Feature'] if 'Asymmetry' in f]\n",
    "\n",
    "selected = []\n",
    "for feat_list, label in [(speed_feats, 'Speed/Efficiency'), \n",
    "                          (variability_feats, 'Variability'),\n",
    "                          (asymmetry_feats, 'Asymmetry')]:\n",
    "    if feat_list:\n",
    "        selected.append(feat_list[0])\n",
    "        print(f\"  {label}: {feat_list[0]}\")\n",
    "\n",
    "# If we don't get 3 distinct categories, fill from top overall\n",
    "while len(selected) < 3 and len(candidate_features) > len(selected):\n",
    "    for f in candidate_features['Feature']:\n",
    "        if f not in selected:\n",
    "            selected.append(f)\n",
    "            break\n",
    "    if len(selected) >= 3:\n",
    "        break\n",
    "\n",
    "print(f\"\\nSelected {len(selected)} features for classification model\")\n",
    "\n",
    "# Prepare data\n",
    "X = results[selected].dropna()\n",
    "valid_idx = X.index\n",
    "y = results.loc[valid_idx, 'Faller'].values\n",
    "X = X.values\n",
    "\n",
    "print(f\"Samples with complete data: {len(X)} (Fallers: {y.sum()}, Non-Fallers: {(y==0).sum()})\")\n",
    "\n",
    "# LOO Cross-Validation\n",
    "scaler = StandardScaler()\n",
    "loo = LeaveOneOut()\n",
    "model = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "y_pred_proba = np.zeros(len(y))\n",
    "y_pred_class = np.zeros(len(y))\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_proba[test_idx] = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_class[test_idx] = model.predict(X_test_scaled)\n",
    "\n",
    "# Results\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"\\n{'═' * 50}\")\n",
    "print(f\"  LOO Cross-Validation Results\")\n",
    "print(f\"{'═' * 50}\")\n",
    "print(f\"  AUC:          {roc_auc:.3f}\")\n",
    "print(f\"  Accuracy:     {(y_pred_class == y).mean():.3f}\")\n",
    "\n",
    "cm = confusion_matrix(y, y_pred_class)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "print(f\"  Sensitivity:  {sensitivity:.3f}\")\n",
    "print(f\"  Specificity:  {specificity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ROC\n",
    "ax1.plot(fpr, tpr, color=GOLD, linewidth=2.5, label=f'AUC = {roc_auc:.3f}')\n",
    "ax1.plot([0, 1], [0, 1], color=GRAY, linewidth=1, linestyle='--', alpha=0.5)\n",
    "ax1.fill_between(fpr, tpr, alpha=0.1, color=GOLD)\n",
    "ax1.set_xlabel('False Positive Rate (1 − Specificity)')\n",
    "ax1.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax1.set_title('ROC Curve — LOO Cross-Validation', fontweight='600')\n",
    "ax1.legend(fontsize=11, loc='lower right')\n",
    "ax1.set_xlim([-0.02, 1.02])\n",
    "ax1.set_ylim([-0.02, 1.02])\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrBr', ax=ax2,\n",
    "            xticklabels=['Non-Faller', 'Faller'],\n",
    "            yticklabels=['Non-Faller', 'Faller'],\n",
    "            annot_kws={'size': 16}, linewidths=1, linecolor='white')\n",
    "ax2.set_xlabel('Predicted', fontsize=11)\n",
    "ax2.set_ylabel('Actual', fontsize=11)\n",
    "ax2.set_title('Confusion Matrix', fontweight='600')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/roc_and_confusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09e99f",
   "metadata": {},
   "source": [
    "## 8. Summary & Key Findings\n",
    "\n",
    "### Methodology\n",
    "- Segmented 6-minute walk test gait cycles into temporal quarters to capture **fatigue-related deterioration patterns**\n",
    "- Engineered features capturing quarter means, fatigue magnitude (Q4−Q1), deterioration rate (slope), and within-quarter variability\n",
    "- Applied assumption-appropriate statistical tests with FDR correction for multiple comparisons\n",
    "- Built a parsimonious logistic regression classifier evaluated with Leave-One-Out cross-validation\n",
    "\n",
    "### Clinical Implications\n",
    "The quarters-based approach to gait analysis may provide **additional discriminative value** beyond traditional overall gait averages. Fatigue-related changes during sustained walking could serve as early indicators of fall risk that are not apparent in short-duration or averaged gait assessments.\n",
    "\n",
    "### Limitations\n",
    "- Small sample size (n=60) limits statistical power and generalizability\n",
    "- Retrospective fall classification (self-reported falls in past year)\n",
    "- Single assessment timepoint\n",
    "- LOO cross-validation may overestimate performance; external validation is needed\n",
    "\n",
    "### Tools & Technologies\n",
    "`Python` · `pandas` · `NumPy` · `SciPy` · `scikit-learn` · `matplotlib` · `seaborn` · `APDM Mobility Lab`\n",
    "\n",
    "---\n",
    "*Analysis by Ferdinand Delgado, PhD — [ferdinanddelgadophd@gmail.com](mailto:ferdinanddelgadophd@gmail.com) · [LinkedIn](https://www.linkedin.com/in/ferdinanddelgado/)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
